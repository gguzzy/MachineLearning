{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We need to import two libraries, in case we don't have it perform the following snippet of code:\n",
        "\n",
        "```\n",
        "$ pip freeze | egrep \"(mlxtend|pandas)\"\n",
        "mlxtend==0.17.0\n",
        "pandas==0.25.1\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "5i8ulDcXhkBf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAMiZ74sFHCL"
      },
      "outputs": [],
      "source": [
        "#importing the necessary libraries\n",
        "\n",
        "import mlxtend\n",
        "import pandas as pd\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXERCISES "
      ],
      "metadata": {
        "id": "a6P6yKrTiEy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.1 Association rules from frequent itemsets"
      ],
      "metadata": {
        "id": "JFMAFh17iIEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. First, you need to load the dataset into memory, using the csv module. Make sure you identify all valid rows. Also consider that rows having an InvoiceNo that starts with C should be discarded, as they indicate that the invoice is about a cancelled purchase.\n",
        "2. Now that you have a dataset of items, you should aggregate it at an “invoice” level. For each invoice (identified by InvoiceNo) there can be multiple items (from multiple rows) in the dataset. For each invoice, you should build a list of all items belonging to it. For the example invoice presented in 1.2.1, you want to build the following list:\n",
        "```\n",
        "[ \"GARDENERS KNEELING PAD KEEP CALM\",\n",
        "\"HOT WATER BOTTLE KEEP CALM\",\n",
        "\"DOORMAT KEEP CALM AND COME IN\" ]\n",
        "```\n",
        "3. You should now have a list (one for each invoice) of lists (each list containing the items bought for that invoice). Now, we need to convert this into a matrix form. Of the many possible formats, we will use the one expected by the Mlxtend library, which is as follows. Given an ordered list of M possible items (in this case, all possible products that can be bought), and given N itemsets (in this case, invoices), we should build a matrix of N rows and M columns. The element at the ith row and jth column should be 1 if the i\n",
        "th itemset (invoice) contains the jth item (product), 0 otherwise. For the following example:\n",
        "```\n",
        "a,b,c\n",
        "b,c\n",
        "a,c,d\n",
        "a,b\n",
        "```\n",
        "The list of all possible items is ```[a, b, c, d]```. As such, the matrix that we will build is the following:\n",
        "```\n",
        "3\n",
        "1 1 1 0\n",
        "0 1 1 0\n",
        "1 0 1 1\n",
        "1 1 0 0\n",
        "```\n",
        "Once we have defined this matrix (as a list of lists), we can use Pandas to convert it to a DataFrame\n",
        "(which is, essentially, a table) with the following code:\n",
        "```\n",
        "import pandas as pd\n",
        "all_items = ['a', 'b', 'c', 'd'] # this is your list of items\n",
        "pa_matrix = [\n",
        "[1,1,1,0],\n",
        "[0,1,1,0],\n",
        "[1,0,1,1],\n",
        "[1,1,0,0]\n",
        "] # this is the matrix you built from the itemsets\n",
        "df = pd.DataFrame(data=pa_matrix, columns=all_items)\n",
        "```\n",
        "4. With the df that you defined in the previous exercise, you can now use the fp_growth function. This\n",
        "function, which is described in the detail in the official documentation. The first argument required is\n",
        "the previously built DataFrame, df. The second is the minimum support (minsup), i.e. the minimum\n",
        "fraction of the entire dataset in which the itemset should show up for it to be considered “frequent”.\n",
        "Try using different values of ```minsup```, such as 0.5, 0.1, 0.05, 0.02, 0.01. How many results do you\n",
        "obtain as minsup varies? You can check the number of frequent itemsets identified and print them\n",
        "all with the following code snipped:\n",
        "```\n",
        "fi = fpgrowth(df, 0.05)\n",
        "print(len(fi))\n",
        "print(fi.to_string())\n",
        "```\n",
        "5. Consider the itemsets extracted for ```minsup = 0.02```. How many items are contained? Which ones\n",
        "would you be considered the most useful?\n",
        "6. Use the value returned by fpgrowth to extract the relevant association rules.\n",
        "7. Extract the association rules from the frequent itemsets extracted with ```minsup = 0.01```. You can\n",
        "find the documentation for ```association_rules()``` on the official documentation. You can use the\n",
        "confidence as the metric to identify the rules, and a minimum threshold of 0.85 (feel free to vary\n",
        "these values and observe how the results vary).\n",
        "8. (*) Rerun the experiments from point 4 with ```apriori()``` (documentation on the official website).\n",
        "Do the results match with the ones found by FP-Growth? Is Apriori faster or slower than FP-Growth?\n",
        "You can measure how long a function call takes with the following code snippet:\n",
        "```\n",
        "import timeit\n",
        "# number=1 means that it executes the function only once\n",
        "timeit.timeit(lambda: apriori(df, 0.01), number=1)\n",
        "4 \n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "bl9oQkqeiKsA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P77MXMFWjyyA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}